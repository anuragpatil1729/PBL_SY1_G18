{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9QfOOKxPWkW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "# ============================================================================\n",
        "# 1. LINEAR REGRESSION FROM SCRATCH\n",
        "# ============================================================================\n",
        "\n",
        "class LinearRegressionScratch:\n",
        "    \"\"\"Linear Regression implementation using gradient descent\"\"\"\n",
        "\n",
        "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iterations = n_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.losses = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Train the linear regression model\"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Initialize weights and bias\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Gradient descent\n",
        "        for i in range(self.n_iterations):\n",
        "            # Forward pass\n",
        "            y_predicted = np.dot(X, self.weights) + self.bias\n",
        "\n",
        "            # Compute loss (MSE)\n",
        "            loss = np.mean((y - y_predicted) ** 2)\n",
        "            self.losses.append(loss)\n",
        "\n",
        "            # Compute gradients\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            # Update parameters\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions\"\"\"\n",
        "        return np.dot(X, self.weights) + self.bias\n",
        "\n",
        "    def save_model(self, filename):\n",
        "        \"\"\"Save model parameters\"\"\"\n",
        "        model_data = {\n",
        "            'weights': self.weights.tolist(),\n",
        "            'bias': float(self.bias)\n",
        "        }\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(model_data, f)\n",
        "        print(f\"Linear Regression model saved to {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 2. SVM FROM SCRATCH (using SMO algorithm simplified)\n",
        "# ============================================================================\n",
        "\n",
        "class SVMScratch:\n",
        "    \"\"\"Support Vector Machine implementation for classification\"\"\"\n",
        "\n",
        "    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.lambda_param = lambda_param\n",
        "        self.n_iterations = n_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.losses = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Train the SVM model using gradient descent\"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Convert labels to -1 and 1\n",
        "        y_ = np.where(y <= 0, -1, 1)\n",
        "\n",
        "        # Initialize weights and bias\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Gradient descent\n",
        "        for i in range(self.n_iterations):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                condition = y_[idx] * (np.dot(x_i, self.weights) - self.bias) >= 1\n",
        "\n",
        "                if condition:\n",
        "                    # No misclassification\n",
        "                    self.weights -= self.learning_rate * (2 * self.lambda_param * self.weights)\n",
        "                else:\n",
        "                    # Misclassification\n",
        "                    self.weights -= self.learning_rate * (\n",
        "                        2 * self.lambda_param * self.weights - np.dot(x_i, y_[idx])\n",
        "                    )\n",
        "                    self.bias -= self.learning_rate * y_[idx]\n",
        "\n",
        "            # Calculate loss (hinge loss)\n",
        "            loss = self._calculate_loss(X, y_)\n",
        "            self.losses.append(loss)\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
        "\n",
        "    def _calculate_loss(self, X, y):\n",
        "        \"\"\"Calculate hinge loss\"\"\"\n",
        "        distances = 1 - y * (np.dot(X, self.weights) - self.bias)\n",
        "        distances[distances < 0] = 0  # max(0, distance)\n",
        "        hinge_loss = self.lambda_param * (np.linalg.norm(self.weights) ** 2) + np.mean(distances)\n",
        "        return hinge_loss\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions\"\"\"\n",
        "        linear_output = np.dot(X, self.weights) - self.bias\n",
        "        return np.sign(linear_output)\n",
        "\n",
        "    def save_model(self, filename):\n",
        "        \"\"\"Save model parameters\"\"\"\n",
        "        model_data = {\n",
        "            'weights': self.weights.tolist(),\n",
        "            'bias': float(self.bias)\n",
        "        }\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(model_data, f)\n",
        "        print(f\"SVM model saved to {filename}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 3. DATA GENERATION & PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "def generate_student_data(n_samples=1000):\n",
        "    \"\"\"Generate synthetic student performance data\"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    data = {\n",
        "        'attendance_percent': np.random.uniform(50, 100, n_samples),\n",
        "        'assignment_avg': np.random.uniform(40, 100, n_samples),\n",
        "        'quiz_avg': np.random.uniform(40, 100, n_samples),\n",
        "        'midterm_score': np.random.uniform(40, 100, n_samples),\n",
        "        'project_score': np.random.uniform(40, 100, n_samples),\n",
        "        'study_hours_weekly': np.random.uniform(0, 20, n_samples),\n",
        "        'participation_level': np.random.randint(1, 6, n_samples),\n",
        "        'previous_gpa': np.random.uniform(1.5, 4.0, n_samples),\n",
        "        'confidence_level': np.random.randint(1, 6, n_samples),\n",
        "        'course_difficulty': np.random.randint(1, 6, n_samples),\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Generate target: final score (weighted formula with noise)\n",
        "    df['final_score'] = (\n",
        "        0.25 * df['midterm_score'] +\n",
        "        0.20 * df['assignment_avg'] +\n",
        "        0.15 * df['quiz_avg'] +\n",
        "        0.10 * df['project_score'] +\n",
        "        0.05 * df['attendance_percent'] +\n",
        "        (df['previous_gpa'] / 4.0) * 10 +\n",
        "        (df['study_hours_weekly'] / 10.0) * 10 +\n",
        "        (df['participation_level'] / 5.0) * 5 +\n",
        "        (df['confidence_level'] - 3) * 1.0 +\n",
        "        (3 - df['course_difficulty']) * 2.0 +\n",
        "        np.random.normal(0, 5, n_samples)  # Add noise\n",
        "    ).clip(0, 100)\n",
        "\n",
        "    # Generate binary classification target: pass/fail (score >= 60)\n",
        "    df['pass_fail'] = (df['final_score'] >= 60).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def prepare_data(df):\n",
        "    \"\"\"Prepare data for training\"\"\"\n",
        "    # Features\n",
        "    feature_cols = [\n",
        "        'attendance_percent', 'assignment_avg', 'quiz_avg', 'midterm_score',\n",
        "        'project_score', 'study_hours_weekly', 'participation_level',\n",
        "        'previous_gpa', 'confidence_level', 'course_difficulty'\n",
        "    ]\n",
        "\n",
        "    X = df[feature_cols].values\n",
        "    y_regression = df['final_score'].values\n",
        "    y_classification = df['pass_fail'].values\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_reg_train, y_reg_test = train_test_split(\n",
        "        X, y_regression, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    _, _, y_clf_train, y_clf_test = train_test_split(\n",
        "        X, y_classification, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Save scaler\n",
        "    with open('scaler.pkl', 'wb') as f:\n",
        "        pickle.dump(scaler, f)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_reg_train, y_reg_test, y_clf_train, y_clf_test, feature_cols\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 4. MODEL TRAINING & EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "def train_and_evaluate_models(X_train, X_test, y_reg_train, y_reg_test, y_clf_train, y_clf_test):\n",
        "    \"\"\"Train and evaluate both models\"\"\"\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"TRAINING LINEAR REGRESSION MODEL\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Train Linear Regression\n",
        "    lr_model = LinearRegressionScratch(learning_rate=0.01, n_iterations=1000)\n",
        "    lr_model.fit(X_train, y_reg_train)\n",
        "\n",
        "    # Evaluate Linear Regression\n",
        "    y_pred_train = lr_model.predict(X_train)\n",
        "    y_pred_test = lr_model.predict(X_test)\n",
        "\n",
        "    train_mse = mean_squared_error(y_reg_train, y_pred_train)\n",
        "    test_mse = mean_squared_error(y_reg_test, y_pred_test)\n",
        "    train_r2 = r2_score(y_reg_train, y_pred_train)\n",
        "    test_r2 = r2_score(y_reg_test, y_pred_test)\n",
        "\n",
        "    print(\"\\n--- Linear Regression Results ---\")\n",
        "    print(f\"Training MSE: {train_mse:.4f}\")\n",
        "    print(f\"Testing MSE: {test_mse:.4f}\")\n",
        "    print(f\"Training R²: {train_r2:.4f}\")\n",
        "    print(f\"Testing R²: {test_r2:.4f}\")\n",
        "\n",
        "    # Save Linear Regression model\n",
        "    lr_model.save_model('linear_regression_model.json')\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING SVM MODEL\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Train SVM\n",
        "    svm_model = SVMScratch(learning_rate=0.001, lambda_param=0.01, n_iterations=1000)\n",
        "    y_clf_train_binary = np.where(y_clf_train == 0, -1, 1)  # Convert to -1, 1\n",
        "    svm_model.fit(X_train, y_clf_train_binary)\n",
        "\n",
        "    # Evaluate SVM\n",
        "    y_pred_train_svm = svm_model.predict(X_train)\n",
        "    y_pred_test_svm = svm_model.predict(X_test)\n",
        "\n",
        "    # Convert predictions back to 0, 1\n",
        "    y_pred_train_svm = np.where(y_pred_train_svm == -1, 0, 1)\n",
        "    y_pred_test_svm = np.where(y_pred_test_svm == -1, 0, 1)\n",
        "\n",
        "    train_acc = accuracy_score(y_clf_train, y_pred_train_svm)\n",
        "    test_acc = accuracy_score(y_clf_test, y_pred_test_svm)\n",
        "\n",
        "    print(\"\\n--- SVM Results ---\")\n",
        "    print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"Testing Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_clf_test, y_pred_test_svm)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Save SVM model\n",
        "    svm_model.save_model('svm_model.json')\n",
        "\n",
        "    return lr_model, svm_model\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 5. VISUALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def plot_results(lr_model, svm_model, X_test, y_reg_test, y_clf_test):\n",
        "    \"\"\"Plot model results\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "    # 1. Linear Regression: Training Loss\n",
        "    axes[0, 0].plot(lr_model.losses, color='blue')\n",
        "    axes[0, 0].set_title('Linear Regression Training Loss')\n",
        "    axes[0, 0].set_xlabel('Iteration')\n",
        "    axes[0, 0].set_ylabel('MSE Loss')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Linear Regression: Predictions vs Actual\n",
        "    y_pred_test = lr_model.predict(X_test)\n",
        "    axes[0, 1].scatter(y_reg_test, y_pred_test, alpha=0.5, color='green')\n",
        "    axes[0, 1].plot([0, 100], [0, 100], 'r--', lw=2)\n",
        "    axes[0, 1].set_title('Linear Regression: Predicted vs Actual')\n",
        "    axes[0, 1].set_xlabel('Actual Score')\n",
        "    axes[0, 1].set_ylabel('Predicted Score')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. SVM: Training Loss\n",
        "    axes[1, 0].plot(svm_model.losses, color='red')\n",
        "    axes[1, 0].set_title('SVM Training Loss')\n",
        "    axes[1, 0].set_xlabel('Iteration')\n",
        "    axes[1, 0].set_ylabel('Hinge Loss')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. SVM: Confusion Matrix Heatmap\n",
        "    y_pred_test_svm = svm_model.predict(X_test)\n",
        "    y_pred_test_svm = np.where(y_pred_test_svm == -1, 0, 1)\n",
        "    cm = confusion_matrix(y_clf_test, y_pred_test_svm)\n",
        "\n",
        "    im = axes[1, 1].imshow(cm, cmap='Blues')\n",
        "    axes[1, 1].set_title('SVM Confusion Matrix')\n",
        "    axes[1, 1].set_xlabel('Predicted')\n",
        "    axes[1, 1].set_ylabel('Actual')\n",
        "    axes[1, 1].set_xticks([0, 1])\n",
        "    axes[1, 1].set_yticks([0, 1])\n",
        "    axes[1, 1].set_xticklabels(['Fail', 'Pass'])\n",
        "    axes[1, 1].set_yticklabels(['Fail', 'Pass'])\n",
        "\n",
        "    # Add text annotations\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            text = axes[1, 1].text(j, i, cm[i, j],\n",
        "                                   ha=\"center\", va=\"center\", color=\"black\", fontsize=20)\n",
        "\n",
        "    plt.colorbar(im, ax=axes[1, 1])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('model_results.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"\\nPlots saved as 'model_results.png'\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 6. FEATURE IMPORTANCE ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "def analyze_feature_importance(lr_model, feature_cols):\n",
        "    \"\"\"Analyze and display feature importance\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"FEATURE IMPORTANCE ANALYSIS (Linear Regression)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Get absolute weights\n",
        "    weights = np.abs(lr_model.weights)\n",
        "\n",
        "    # Sort features by importance\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_cols,\n",
        "        'Weight': lr_model.weights,\n",
        "        'Absolute Weight': weights\n",
        "    }).sort_values('Absolute Weight', ascending=False)\n",
        "\n",
        "    print(\"\\n\", importance_df.to_string(index=False))\n",
        "\n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(importance_df['Feature'], importance_df['Absolute Weight'], color='skyblue')\n",
        "    plt.xlabel('Absolute Weight (Importance)')\n",
        "    plt.title('Feature Importance in Student Performance Prediction')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"\\nFeature importance plot saved as 'feature_importance.png'\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 7. MODEL PREDICTION FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def predict_student_performance(lr_model, svm_model, scaler, student_data):\n",
        "    \"\"\"Make prediction for a new student\"\"\"\n",
        "    # Prepare input\n",
        "    X_new = np.array([list(student_data.values())])\n",
        "    X_new_scaled = scaler.transform(X_new)\n",
        "\n",
        "    # Linear Regression prediction\n",
        "    predicted_score = lr_model.predict(X_new_scaled)[0]\n",
        "    predicted_score = np.clip(predicted_score, 0, 100)\n",
        "\n",
        "    # SVM prediction\n",
        "    pass_fail_pred = svm_model.predict(X_new_scaled)[0]\n",
        "    pass_fail = \"Pass\" if pass_fail_pred == 1 else \"Fail\"\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"STUDENT PERFORMANCE PREDICTION\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\nInput Data:\")\n",
        "    for key, value in student_data.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    print(f\"\\nPredicted Final Score: {predicted_score:.2f}%\")\n",
        "    print(f\"Predicted Outcome: {pass_fail}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    return predicted_score, pass_fail\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# 8. MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 80)\n",
        "    print(\"STUDENT PERFORMANCE PREDICTION USING ML FROM SCRATCH\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Generate and prepare data\n",
        "    print(\"\\n1. Generating synthetic student data...\")\n",
        "    df = generate_student_data(n_samples=1000)\n",
        "    print(f\"Generated {len(df)} student records\")\n",
        "    print(\"\\nData sample:\")\n",
        "    print(df.head())\n",
        "\n",
        "    print(\"\\n2. Preparing data for training...\")\n",
        "    X_train, X_test, y_reg_train, y_reg_test, y_clf_train, y_clf_test, feature_cols = prepare_data(df)\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Testing samples: {len(X_test)}\")\n",
        "\n",
        "    # Train models\n",
        "    print(\"\\n3. Training models...\")\n",
        "    lr_model, svm_model = train_and_evaluate_models(\n",
        "        X_train, X_test, y_reg_train, y_reg_test, y_clf_train, y_clf_test\n",
        "    )\n",
        "\n",
        "    # Visualize results\n",
        "    print(\"\\n4. Creating visualizations...\")\n",
        "    plot_results(lr_model, svm_model, X_test, y_reg_test, y_clf_test)\n",
        "\n",
        "    # Feature importance\n",
        "    print(\"\\n5. Analyzing feature importance...\")\n",
        "    analyze_feature_importance(lr_model, feature_cols)\n",
        "\n",
        "    # Test prediction\n",
        "    print(\"\\n6. Testing prediction on a sample student...\")\n",
        "    with open('scaler.pkl', 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "\n",
        "    sample_student = {\n",
        "        'attendance_percent': 85.0,\n",
        "        'assignment_avg': 78.0,\n",
        "        'quiz_avg': 75.0,\n",
        "        'midterm_score': 72.0,\n",
        "        'project_score': 80.0,\n",
        "        'study_hours_weekly': 8.0,\n",
        "        'participation_level': 4,\n",
        "        'previous_gpa': 3.2,\n",
        "        'confidence_level': 4,\n",
        "        'course_difficulty': 3\n",
        "    }\n",
        "\n",
        "    predict_student_performance(lr_model, svm_model, scaler, sample_student)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\nGenerated files:\")\n",
        "    print(\"  - linear_regression_model.json\")\n",
        "    print(\"  - svm_model.json\")\n",
        "    print(\"  - scaler.pkl\")\n",
        "    print(\"  - model_results.png\")\n",
        "    print(\"  - feature_importance.png\")\n",
        "    print(\"=\" * 80)"
      ]
    }
  ]
}